{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantics_with_BERT (1).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dG_avmzcVER1",
        "XFfyRZ25VESF",
        "kXQTyIOHVESL",
        "uYagm244VESO",
        "pwz77KgPVESP",
        "VwORAuZyE0yK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2afb482534e54d0a9611a775af702fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_93264af83e8c4dce9ba85765d467a3e8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_36300cfec54c44d3b06cda8e10449be0",
              "IPY_MODEL_8a421fd11c834b358aa23e6ed4c2ee31",
              "IPY_MODEL_8545870f3596482394b7751b8fe94970"
            ]
          }
        },
        "93264af83e8c4dce9ba85765d467a3e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36300cfec54c44d3b06cda8e10449be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fc55a32d3a104f2196f1e63ab8f59bc9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f729523d91a242628fbbc83d329c92f4"
          }
        },
        "8a421fd11c834b358aa23e6ed4c2ee31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2e87713dd9f94b77a94f388e72748ed9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 690,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 690,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90701485ff3549f2a9b973ee19af549b"
          }
        },
        "8545870f3596482394b7751b8fe94970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_841a7438f9a64f86bfd162998270066f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 690/690 [00:00&lt;00:00, 15.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38a578b128d049709cc346dc4f72e6a2"
          }
        },
        "fc55a32d3a104f2196f1e63ab8f59bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f729523d91a242628fbbc83d329c92f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e87713dd9f94b77a94f388e72748ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90701485ff3549f2a9b973ee19af549b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "841a7438f9a64f86bfd162998270066f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38a578b128d049709cc346dc4f72e6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuM2vOE8T6Kb"
      },
      "source": [
        "##**THIS CODE COVERS:**\n",
        "\n",
        "\n",
        "*   Sentence Embeddings With BERT and Bi-Directional LSTM layers\n",
        "*   By using K-means, clustering similiar sentences\n",
        "*   Fine-Tuning of Model\n",
        "*   Semantic Similarity between Sentences\n",
        "*   Applying S-Bert using Sentence Transformers for Semantic Search through corpus.\n",
        "\n",
        "***By Insiyah Talib Hussain***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12be7c6a-a8a1-4043-b3f7-17f601b78719"
      },
      "source": [
        "!pip install wget\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=dae7e3a46cdd72c1047d64f2c06ba9b0d771d68339f9d31ce9e424d16a473131\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 47.7 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 45.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JZyVmfOChff",
        "outputId": "e280b2a3-a003-4de7-beaf-61b45d0ed695"
      },
      "source": [
        "#Import Libraries\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import wget\n",
        "import os\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import transformers\n",
        "!pip3 install sentence_transformers\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "#!pip3 install libomp\n",
        "#sudo apt-get install libomp-dev\n",
        "!apt install libomp-dev\n",
        "!python -m pip install --upgrade faiss faiss-gpu\n",
        "import faiss\n",
        "from pprint import pprint"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.19.5)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.62.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.10.0+cu111)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.96)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: tokenizers>=0.10.3 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.10.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.2.5)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.0.19)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence_transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (4.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.0.46)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.5.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.0.1)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libomp5\n",
            "Suggested packages:\n",
            "  libomp-doc\n",
            "The following NEW packages will be installed:\n",
            "  libomp-dev libomp5\n",
            "0 upgraded, 2 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 239 kB of archives.\n",
            "After this operation, 804 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp-dev amd64 5.0.1-1 [5,088 B]\n",
            "Fetched 239 kB in 1s (265 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 155047 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Selecting previously unselected package libomp-dev.\n",
            "Preparing to unpack .../libomp-dev_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp-dev (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp-dev (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: faiss in /usr/local/lib/python3.7/dist-packages (1.5.3)\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.1.post2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 89.7 MB 9.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from faiss) (1.19.5)\n",
            "Installing collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.1.post2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncd2EenRjyNX",
        "outputId": "b363547f-5dba-4368-b09f-5924a7fd1a82"
      },
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9HES2XjjzKJ",
        "outputId": "8809feb5-e277-491e-8138-7ac90ddd2f53"
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG_avmzcVER1"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Semantic Similarity is the task of determining how similar\n",
        "two sentences are, in terms of what they mean.\n",
        "This example demonstrates the use of SNLI (Stanford Natural Language Inference) Corpus\n",
        "to predict sentence semantic similarity with Transformers.\n",
        "We will fine-tune a BERT model that takes two sentences as inputs\n",
        "and that outputs a similarity score for these two sentences.\n",
        "\n",
        "### References\n",
        "\n",
        "* [BERT](https://arxiv.org/pdf/1810.04805.pdf)\n",
        "* [SNLI](https://nlp.stanford.edu/projects/snli/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnGUX67qC87p",
        "outputId": "03bec028-8793-41a6-f1df-f57640c67550"
      },
      "source": [
        "labels = [\"contradiction\", \"entailment\", \"neutral\"]\n",
        "max_length = 128  # Maximum length of input sentence to the model.\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "!curl -LO https://raw.githubusercontent.com/MohamadMerchant/SNLI/master/data.tar.gz\n",
        "!tar -xvzf data.tar.gz\n",
        "train_df = pd.read_csv(\"SNLI_Corpus/snli_1.0_train.csv\", nrows=100000)\n",
        "valid_df = pd.read_csv(\"SNLI_Corpus/snli_1.0_dev.csv\")\n",
        "test_df = pd.read_csv(\"SNLI_Corpus/snli_1.0_test.csv\")\n",
        "print(\"Train Target Distribution\")\n",
        "print(train_df.similarity.value_counts())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 11.1M  100 11.1M    0     0  30.3M      0 --:--:-- --:--:-- --:--:-- 30.3M\n",
            "SNLI_Corpus/\n",
            "SNLI_Corpus/snli_1.0_dev.csv\n",
            "SNLI_Corpus/snli_1.0_train.csv\n",
            "SNLI_Corpus/snli_1.0_test.csv\n",
            "Train Target Distribution\n",
            "entailment       33385\n",
            "contradiction    33311\n",
            "neutral          33194\n",
            "-                  110\n",
            "Name: similarity, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwPS4DNnDG1B",
        "outputId": "e287606d-f2fd-4f1e-d958-423017433ccb"
      },
      "source": [
        "print(f\"Sentence1: {train_df.loc[1, 'sentence1']}\")\n",
        "print(f\"Sentence2: {train_df.loc[1, 'sentence2']}\")\n",
        "print(f\"Similarity: {train_df.loc[1, 'similarity']}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence1: A person on a horse jumps over a broken down airplane.\n",
            "Sentence2: A person is at a diner, ordering an omelette.\n",
            "Similarity: contradiction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFfyRZ25VESF"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5YPGHpoDJV1",
        "outputId": "5ca9f790-22db-4472-9bb7-9493b6120022"
      },
      "source": [
        "# We have some NaN entries in our train data, we will simply drop them.\n",
        "print(\"Number of missing values\")\n",
        "print(train_df.isnull().sum())\n",
        "train_df.dropna(axis=0, inplace=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of missing values\n",
            "similarity    0\n",
            "sentence1     0\n",
            "sentence2     3\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI-te9ecDRWc",
        "outputId": "48c2b384-8857-471d-d65d-644c45db7fd1"
      },
      "source": [
        "print(\"Train Target Distribution\")\n",
        "print(train_df.similarity.value_counts())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Target Distribution\n",
            "entailment       33384\n",
            "contradiction    33310\n",
            "neutral          33193\n",
            "-                  110\n",
            "Name: similarity, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqk51sUnDTWN",
        "outputId": "34394b1c-40c1-43cc-9b40-a7e74b7577ef"
      },
      "source": [
        "print(\"Validation Target Distribution\")\n",
        "print(valid_df.similarity.value_counts())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Target Distribution\n",
            "entailment       3329\n",
            "contradiction    3278\n",
            "neutral          3235\n",
            "-                 158\n",
            "Name: similarity, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOY9EvEWDVJf"
      },
      "source": [
        "train_df = (\n",
        "    train_df[train_df.similarity != \"-\"]\n",
        "    .sample(frac=1.0, random_state=42)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "valid_df = (\n",
        "    valid_df[valid_df.similarity != \"-\"]\n",
        "    .sample(frac=1.0, random_state=42)\n",
        "    .reset_index(drop=True)\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbZ1cyk8DWcE"
      },
      "source": [
        "train_df[\"label\"] = train_df[\"similarity\"].apply(\n",
        "    lambda x: 0 if x == \"contradiction\" else 1 if x == \"entailment\" else 2\n",
        ")\n",
        "y_train = tf.keras.utils.to_categorical(train_df.label, num_classes=3)\n",
        "\n",
        "valid_df[\"label\"] = valid_df[\"similarity\"].apply(\n",
        "    lambda x: 0 if x == \"contradiction\" else 1 if x == \"entailment\" else 2\n",
        ")\n",
        "y_val = tf.keras.utils.to_categorical(valid_df.label, num_classes=3)\n",
        "\n",
        "test_df[\"label\"] = test_df[\"similarity\"].apply(\n",
        "    lambda x: 0 if x == \"contradiction\" else 1 if x == \"entailment\" else 2\n",
        ")\n",
        "y_test = tf.keras.utils.to_categorical(test_df.label, num_classes=3)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXQTyIOHVESL"
      },
      "source": [
        "## Keras Custom Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1MDtkgvDZNM"
      },
      "source": [
        "\n",
        "class BertSemanticDataGenerator(tf.keras.utils.Sequence):\n",
        "    \"\"\"Generates batches of data.\n",
        "\n",
        "    Args:\n",
        "        sentence_pairs: Array of premise and hypothesis input sentences.\n",
        "        labels: Array of labels.\n",
        "        batch_size: Integer batch size.\n",
        "        shuffle: boolean, whether to shuffle the data.\n",
        "        include_targets: boolean, whether to incude the labels.\n",
        "\n",
        "    Returns:\n",
        "        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n",
        "        (or just `[input_ids, attention_mask, `token_type_ids]`\n",
        "         if `include_targets=False`)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        sentence_pairs,\n",
        "        labels,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        include_targets=True,\n",
        "    ):\n",
        "        self.sentence_pairs = sentence_pairs\n",
        "        self.labels = labels\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_size = batch_size\n",
        "        self.include_targets = include_targets\n",
        "        # Load our BERT Tokenizer to encode the text.\n",
        "        # We will use base-base-uncased pretrained model.\n",
        "        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n",
        "            \"bert-base-uncased\", do_lower_case=True\n",
        "        )\n",
        "        self.indexes = np.arange(len(self.sentence_pairs))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Denotes the number of batches per epoch.\n",
        "        return len(self.sentence_pairs) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Retrieves the batch of index.\n",
        "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        sentence_pairs = self.sentence_pairs[indexes]\n",
        "\n",
        "        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n",
        "        # encoded together and separated by [SEP] token.\n",
        "        encoded = self.tokenizer.batch_encode_plus(\n",
        "            sentence_pairs.tolist(),\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=True,\n",
        "            pad_to_max_length=True,\n",
        "            return_tensors=\"tf\",\n",
        "        )\n",
        "\n",
        "        # Convert batch of encoded features to numpy array.\n",
        "        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
        "        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
        "        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n",
        "\n",
        "        # Set to true if data generator is used for training/validation.\n",
        "        if self.include_targets:\n",
        "            labels = np.array(self.labels[indexes], dtype=\"int32\")\n",
        "            return [input_ids, attention_masks, token_type_ids], labels\n",
        "        else:\n",
        "            return [input_ids, attention_masks, token_type_ids]\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Shuffle indexes after each epoch if shuffle is set to True.\n",
        "        if self.shuffle:\n",
        "            np.random.RandomState(42).shuffle(self.indexes)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F1QV4iTDfxe",
        "outputId": "2b4179dd-4477-4095-8576-99c26074721a"
      },
      "source": [
        "# Create the model under a distribution strategy scope.\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with strategy.scope():\n",
        "    # Encoded token ids from BERT tokenizer.\n",
        "    input_ids = tf.keras.layers.Input(\n",
        "        shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n",
        "    )\n",
        "    # Attention masks indicates to the model which tokens should be attended to.\n",
        "    attention_masks = tf.keras.layers.Input(\n",
        "        shape=(max_length,), dtype=tf.int32, name=\"attention_masks\"\n",
        "    )\n",
        "    # Token type ids are binary masks identifying different sequences in the model.\n",
        "    token_type_ids = tf.keras.layers.Input(\n",
        "        shape=(max_length,), dtype=tf.int32, name=\"token_type_ids\"\n",
        "    )\n",
        "\n",
        "    # Loading pretrained BERT model.\n",
        "    \n",
        "    bert_model = transformers.TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
        "    # Freeze the BERT model to reuse the pretrained features without modifying them.\n",
        "    bert_model.trainable = False\n",
        "\n",
        "    sequence_output, pooled_output = bert_model(\n",
        "        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n",
        "    )\n",
        "    bert_output = bert_model(\n",
        "    input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n",
        ")\n",
        "    sequence_output = bert_output.last_hidden_state\n",
        "    pooled_output = bert_output.pooler_output\n",
        "    # Add trainable layers on top of frozen layers to adapt the pretrained features on the new data.\n",
        "    bi_lstm = tf.keras.layers.Bidirectional(\n",
        "        tf.keras.layers.LSTM(64, return_sequences=True)\n",
        "    )(sequence_output)\n",
        "    # Applying hybrid pooling approach to bi_lstm sequence output.\n",
        "    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_lstm)\n",
        "    max_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_lstm)\n",
        "    concat = tf.keras.layers.concatenate([avg_pool, max_pool])\n",
        "    dropout = tf.keras.layers.Dropout(0.3)(concat)\n",
        "    output = tf.keras.layers.Dense(3, activation=\"softmax\")(dropout)\n",
        "    model = tf.keras.models.Model(\n",
        "        inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"acc\"],\n",
        "    )\n",
        "\n",
        "\n",
        "print(f\"Strategy: {strategy}\")\n",
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f817fa5a310>\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_masks (InputLayer)    [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "token_type_ids (InputLayer)     [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_5 (TFBertModel)   TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n",
            "                                                                 attention_masks[0][0]            \n",
            "                                                                 token_type_ids[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 128, 128)     426496      tf_bert_model_5[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_1 (Glo (None, 128)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           global_average_pooling1d_1[0][0] \n",
            "                                                                 global_max_pooling1d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_223 (Dropout)           (None, 256)          0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 3)            771         dropout_223[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 109,909,507\n",
            "Trainable params: 427,267\n",
            "Non-trainable params: 109,482,240\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLC8OPK9DiFi"
      },
      "source": [
        "train_data = BertSemanticDataGenerator(\n",
        "    train_df[[\"sentence1\", \"sentence2\"]].values.astype(\"str\"),\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "valid_data = BertSemanticDataGenerator(\n",
        "    valid_df[[\"sentence1\", \"sentence2\"]].values.astype(\"str\"),\n",
        "    y_val,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        ")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpJI-zM4tKff",
        "outputId": "79a97533-f2f8-43f9-cde1-498951de1f1b"
      },
      "source": [
        "cl=[]\n",
        "#pip install - U sentence - transformers\n",
        "!pip3 install sentence_transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "embedder = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Corpus with example sentences\n",
        "corpus=train_data.sentence_pairs.tolist()[:500]\n",
        "corpus_embeddings = embedder.encode(corpus)\n",
        "\n",
        "# Perform kmean clustering\n",
        "num_clusters = 5\n",
        "clustering_model = KMeans(n_clusters=num_clusters)\n",
        "clustering_model.fit(corpus_embeddings)\n",
        "cluster_assignment = clustering_model.labels_\n",
        "\n",
        "clustered_sentences = [[] for i in range(num_clusters)]\n",
        "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
        "\n",
        "for i, cluster in enumerate(clustered_sentences):\n",
        "    print(\"Cluster \", i+1)\n",
        "    print(cluster)\n",
        "d=pd.DataFrame(clustered_sentences[1:],columns=clustered_sentences[0])\n",
        "d"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.9.0+cu111)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.19.5)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.0.19)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.2.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.62.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.11.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.96)\n",
            "Requirement already satisfied: tokenizers>=0.10.3 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.10.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence_transformers) (3.7.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.0.46)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (4.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n",
            "Cluster  1\n",
            "[['Two male clowns, one in a plaid suit and the other in black, performing a musical number in a theater setting.', 'The clowns are in the dressing room.'], ['A blond woman wearing a green shirt and blue jeans walks away.', 'A woman walks away in anger.'], ['A white female wearing white shorts and yellow top throws a stick in a nature scene.', 'A woman is wearing shorts'], ['Some Japanese people enjoy a fireworks shows from a local street.', 'A group of people are standing outside at night.'], ['A woman smiling while raising her right hand.', 'The grumpy man left the building.'], ['Two women in flowered Asian garb pose and smile.', 'two women take a picture'], ['A woman attempts to mini-golf while water pouring down from above interferes.', 'A woman on a date.'], ['Two clowns speak into a microphone.', 'Two clowns talking.'], ['A group stands in the distance while the sky casts interesting light on some clouds.', 'A group of people watching a movie.'], ['A girl is standing in a field pushing up her hat with one finger and her hand is covering most of her face.', 'A girl is standing in a field pushing up her baseball hat with one finger and her hand is covering most of her face.'], ['Woman with stuffed animal display.', 'A woman is selling fruit.'], ['There is a woman in a black jacket and sunglasses and a man in a white shirt with his back turned.', 'Two people of opposite genders are not facing each other.'], ['A group of people gather and holding different types of flags.', 'People are watching a parade while eating ice cream.'], ['A man holding a cellphone and a woman holding a shopping bag stand in front of a wall covered in street art.', \"A man doesn't own a cellphone.\"], ['Workers sell Coca Cola Products to customers.', 'The workers are selling Coca Cola Products to help raise sales.'], ['A native person doing a dance.', 'a native american performing a traditional dance'], ['Several people dressed in brightly colored clothing are standing in a row.', 'A group of people are standing outside in a row.'], ['A young woman wearing sunglasses and several necklaces drinks from a bottle of water in an outdoor setting.', 'The woman is sitting on a couch at home.'], ['A white-haired woman in cooking vegetables.', 'The vegetables being cooked are onions and peppers.'], ['Group of men and women waiting for a bus.', 'Some people wait for a greyhound bus.'], ['Two people hugging while two other people stare down on them.', 'The people are looking down on the hugging couple.'], ['Two blond-hair ladies are sitting on a park bench near a body of water.', 'Two ladies are at work in the cubicle farm hoping the day ends quickly.'], [\"A couple on a beach, the woman is touching the man's face.\", 'Two lovers are sharing an intimate moment on the beach.'], ['A man and a woman are sharing a meal at an outside restaurant.', 'a man and a woman are on their first date'], ['A crowd of people looking at something.', 'Crowd of people looking at something'], ['Three people in costume walking on sidewalk.', 'Three people in costume are actors.'], ['A band of women plays music on a brightly-bannered stage as a lone young woman with brown hair looks on.', 'There is a sad woman.'], ['A girl and a guy sitting on the ground while the girl is blowing bubbles.', 'A girl is blowing bubbles.'], ['A young woman is posing on a mini-scooter while another woman sets up a camera in a park.', 'The photographer is being paid by the woman posing.'], ['A basketball team of 8 girls is doing a hand huddle.', 'The basketball team of 8 girls are african american.'], ['A woman and two girls dressed in pink.', 'Three people are at a dance.'], ['A woman slipping backwards in the snow.', 'the woman slips on a bug'], ['Two women are looking at a monitor with a long antenna.', 'Two people looked at a screen with an antenna.'], ['A man and a woman holding a blue and green slushy on a busy street corner.', 'A man and woman hold a slushy.'], ['A woman wearing a blue skirt, high heels, a white shirt, green jacket and headband is walking out of a tunnel.', 'The woman is walking outside.'], ['A black woman peering through a telescope with several people in the background in the park.', 'A woman is looking through a telescope.'], ['A band playing music together.', 'The band formed last year.'], ['An intimate setting with low lighting, draped doors and tables with small groups of men and women smiling and drinking.', 'There are more than 2 people.'], ['Two people sitting in hats and shades.', 'Two people are sitting in the sun with hats and sunglasses on.'], ['An attractive girl with a cigarette in one hand leaning over and showing lots of cleavage.', 'A pretty girl holds a cigarette'], ['A man and woman are in the kitchen and a package of Challenge butter is in the foreground.', 'A man and woman are not in the kitchen'], [\"Bride eating wedding cake from her new husband's shirt.\", \"Bride eating wedding cake from her husband's shirt.\"], ['Three women paddle their small boats along the river.', 'People riding on the river.'], ['A man is standing in a room in which various pots and crafts are scattered behind him with another man while a group of people enter the room behind him.', 'Woman in working with arts and crafts'], ['Three musicians are posing for a photograph in a soundproof studio booth.', 'The musicians are playing in a concert.'], ['Woman in a pink shirt walking through the bushes.', 'A woman wearing a pink top looking for a lost pet in the bushes.'], ['Woman holding a baby shopping for books', 'The woman is shopping for books for her baby.'], ['Students working in art class.', 'The students are indoors.'], ['An art student uses a blue Sharpie to create a pattern on thick, white poster board.', 'A student knits a scarf.'], ['A group of men and women sit at laptop computers inside a coffee shop.', 'The group is drinking coffee.'], ['A man and a woman are spray painting a wall.', 'A man and woman is kissing.'], ['Two girls, one with a pink flower in her hair, reading a letter sitting on a stone ledge.', 'The girls are in a car.'], ['A group of people are riding on a tour bus and viewing something interesting out the window.', 'People are looking out the window.'], ['A woman sitting in a chair attached to a long wooden arm with a crowd gathered around her.', 'The woman is standing on stage.'], ['A couple shares a kiss on the sidewalk in front of a large building.', 'A couple kissing outside a large building.'], ['A young woman packs belongings into a black suitcase.', 'A young woman distributes belongings into a black box.'], ['A man and a woman are walking on a street at the top of a hill.', 'A married couple walks atop a hill.'], ['This is a view of time square in New York.', 'Several ads for plays are visible.'], ['A male and a female dancing on a stage.', 'couple sleeping'], ['The woman is dressed in all white swinging a tennis racket.', 'A man is falling down stairs.'], ['Two young people are standing in the doorway of a room filled with pink, white, and red balloons.', 'The people are at a surprise party.'], ['a woman in a white uniform is sorting nuts behind a glass counter.', 'The woman in white sorts nuts for the customer.'], ['Women in colorful dresses are dancing.', 'THe woman is dancing'], ['students studying at the pavilion restaurant in their campus getting ready for exams.', 'Students eating at the pavilion restaurant in their campus slacking on their school work.'], ['A woman in a denim jacket and a bearded man with a red shirt and tan jacket are walking along a street.', 'A woman in a dress and a bearded dog are running.'], ['A group of women dressed for roller derby are standing and sitting in a group.', 'Roller derby team is congregating together.'], ['Some people are standing alone on the beach in their swimsuits.', 'The beach is near empty except for a few people standing together.'], ['A couple on the stairs are photographing a man and woman embracing in front of a building.', 'There is a photo shoot occurring.'], ['A woman sits on a crate by her baskets of fruit.', 'A woman is standing at a market.'], ['An older woman with blond-hair and sunglasses leans against a railing outdoors.', 'The woman is dancing on the table.'], ['The women have pink bunny ears on their heads.', 'The women are both black.'], ['There are many people with black hair heading through some doors and a few coming out.', 'People are going into and out of doors.'], ['Four people posing for a picture', 'People are posing for a picture.'], ['Several women and men are lifting their arms straight up above their heads.', 'People raise their arms'], ['Asian singer performs live jazz music in a nightclub.', 'Asian singer performs jazz live.'], ['A woman from India origin standing while making yarn.', 'A woman is making yarn.'], ['Two people leaf-blow a sidewalk.', 'these people are cleaning something'], ['A woman wearing a gray jacket and blue shirt, and a man wearing a yellow shirt and blue pants are standing on the side of the road in a city setting, waiting for a public bus to come by and pick them up, or for the bus to pass so they can cross the road.', 'The man and woman are dressed in colorful attire.'], ['A woman in a field of flowers is blowing on them.', 'A woman is outside.'], ['A couple are dancing while others are watching a concert in a bandstand.', 'A couple is eating dinner.'], [\"A woman in a coat walking by a women's clothing store.\", 'a woman is walking'], ['A group of people are surrounding a person who is lying down.', 'There are people gathered together in a group.'], ['the reflection of a young couple in a train window with onlookers and a old asian man sitting on the bench.', 'a couple is reflected in a window.'], ['A mother is adjusting the clothing of her child.', 'The woman is on the moon'], ['A group of Asians and one Anglo stand outside bundled in winter clothing.', 'People are standing outside.'], ['A young woman wearing tan pants is touching her shoe.', 'Woman getting dressed for a date'], ['People with braided hair are gathered around.', 'The group of people are talking to each other.'], ['This girl is singing in front of many people wearing a nice fashionable dress.', 'an attractive lady sings an opera to patrons at the theater'], ['A woman wearing a black shirt walks among a crowd in a city.', 'There is a woman walking in the city.'], ['Woman in yellow costume smiling.', 'Woman in Halloween costume smiling.'], ['Musicians playing to a crowd of people on the street.', 'The street is long.'], ['Next to a green field, young blond woman sitting outside on a gray trunk applying makeup to her face.', 'The woman is wearing Covergirl makeup.'], ['You have a photo of people ice skating in front of a brown building with the name Adobe at the top.', 'The people are skating.'], ['A girl wearing a red and black striped shirt is sitting on a brick wall near a flower garden.', 'The flower garden has sunflowers in it.'], ['Roller derby girl skating with others.', 'A girl is skating'], ['A large group of people look as if they are in a band, and they are practicing classical music with guitars, violins, and cellos.', 'Most of the musicians are sitting down.'], ['A young woman getting her haircut.', 'A woman is cutting her hair'], ['A man and woman kiss in a train window.', 'People kiss on a train.'], ['A woman is preparing a soup on a stove.', 'The stove is turned on.'], ['Six women are sitting at a table together in front of a bookshelf.', 'Men are sitting at a table in front of a bookshelf.'], ['Two young ladies review the pictures taken in their digital camera.', 'Two young ladies are running.'], ['One girl is helping another to take a picture with a digital camera.', 'A girl is showing another girl how her camera works.'], ['A group of women wearing all black uniforms play various stringed instruments.', 'A group of women are performing a classical song on their stringed instruments.'], ['Two men and one woman are dressed in costume hats.', 'the people are in costumes'], ['A woman wearing all white and eating, walks next to a man holding a briefcase.', 'A married couple is sleeping.'], ['A family enjoying the Christmas holiday together in a living room.', 'A family enjoying Christmas.'], ['Picture of a train and people in a subway.', 'People are standing in the subway.'], ['A man and woman are riding a motor scooter.', 'People riding a scooter.'], ['A lead choir singer with the rest of the choir singing in the background of a concert hall.', 'people are singing'], ['Two young girls lay, face down, on grass and face the camera as they listen to an iPod near a folding chair and several purses.', 'Two young girls listening to alien speeches.'], ['A train station is surrounded by pedestrians.', 'People stand all around the station'], ['A girl plugging her nose underwater.', 'The woman underwater doe not like to get water in her nose so she plugs it'], ['A woman in a polka-dot shirt and black boots is walking down the street and being approached by a man in a black jacket and jeans.', 'a lady walks down the street approaching a man in black'], ['A woman in a long dress is outside walking with a green laundry basket in her hands in front of a brick building with an \"apartment for rent\" sign.', 'A man is carrying a bunch of fruit in a laundry basket.'], ['A woman in an American jumpsuit is providing medical attention to an elderly person.', 'There is a woman giving assistance to someone.'], ['People are sweeping a sidewalk.', 'People are at a rock concert.'], ['In this group of people, two men are in military camouflage and one is shaking hands with a woman.', 'There are two men in military camouflage.'], ['Two people enjoy the tranquility on a riverbank.', 'Two people are watching the river.'], ['An Indian woman in traditional clothing cooks vegetables on her stove.', 'A woman is driving a car.'], ['Two guitar players make their way back from the beach.', 'Two women are making their way back from the beach.'], ['Several people walking along a curved walkway inside of a building with various advertisements.', 'There were a lot of ads when the people were entering the building'], ['Young woman lifts arms in shadow, ocean and sunset in background.', 'the young woman is outside'], ['Woman in red shirt and sunglasses gives candy to her daughter who is wearing a crown.', 'A woman in a red shirt gives her daughter her backpack for school.'], ['Two women wearing glasses are talking.', 'The women speak the same language.'], ['A crowded street, in an Asian country, where the buildings are dominated by the Seiko building.', 'The street is empty.'], ['Two dancers performing a traditional ethnic dance.', 'A couple of people are dancing.'], ['A girl dressed up in a red dress and a hat with long brown hair.', 'A girl is dressed up for church.'], ['Two people pose for the camera.', 'Two people are yelling.'], ['Blond mother holding her child in her arms at the aquarium.', 'A person holding a child.'], ['A man with a cigarette talks to a woman with a cigarette.', 'A man and woman are both enjoying a cigarette.'], ['Two teenage boys and one teenage girl sitting on the steps of a pool or canal.', 'A teenage couple and their friend sit on the edge of the pool.'], ['Six people in a boat floating in the water.', 'People floating in water'], ['A group of elderly people are meeting together in a room.', 'The elderly people meet up in a room.'], ['A group of young adults coordinate a jumping picture while in the woods near a river.', 'A group of young adults are spending time in nature.'], ['Women in colorful costumes dance in the street in front of a McDonalds.', 'Women are dancing in the street.'], ['A man is at a dinner with friends.', 'The woman is getting fitted for new glasses.'], ['People in a meeting setting paying attention to a speaker in an orange shirt.', 'The people are listening to music on their CD players.'], ['A group of people dressed in festive outfits is gathered outside building.', 'A crowd of people outside.'], ['A woman wearing black glasses is sharing sweets with a toddler girl wearing a princess hat.', 'A father eats breakfast with a teenage boy.'], [\"A model posing to look as if she's a real female soccer player.\", 'A woman is trying to model for a sports magazine.'], ['A woman with a brown coat and a woman with a black top stand along displays of oranges, apples, and other fruits.', 'The two women were selling fruit to people who passed by'], ['A middle-aged woman attired in a red skirt, brown blouse engaged in making pottery.', 'A woman is taking a pottery class.'], ['A blond girl in a green patterned shirt has her hand raised.', 'The girl is in a classroom.'], ['Brightly colored kayaks carrying two people each are paddled down a tree lined river.', 'The two friends are kayaking on their nature trip.'], ['A man is playing the accordion.', 'The woman is playing the flute.'], ['Several people walking along a curved walkway inside of a building with various advertisements.', 'People are walking along a curved walkway'], ['A group of people dressed in festive outfits is gathered outside building.', 'A crowd of people outside a party.'], ['A band is playing under a tent while people watch them play from chairs several yards away.', 'The band is playing at a wedding ceremony.'], ['A woman is dancing and a man is holding an oar.', 'A woman is sleep.'], ['A young girl faces a white and black wall in a red-carpeted room.', 'The girl is in timeout.'], ['A view of a marketplace full of people in an asian country.', 'A busy Asian Market where people are doing business.'], ['The silhouette of three people in front of a wall.', 'The people are by the wall.'], ['Cooks are working in a kitchen.', 'People are sitting on an airplane.'], ['The woman has a blue shirt on with a kid to her side, and she is making hamburgers.', 'The woman was making dinner for her family'], ['A woman in a pink shirt walks in front of a pink mural.', 'The woman has on a shirt.'], ['A young man is talking with an older woman while drinking wine.', 'A girl is talking with an older woman while drinking wine.'], ['A daughter, wearing all pink, watches her mother conduct the demonstration.', 'The mom is old'], ['Baskets of fresh cabbage, tomatoes, beans and other produce sit outside in an open air market.', 'A basket of apples and oranges for sale.'], ['Two women wearing cowboy hats lugging big bags after a shopping trip.', 'A mother and daughter have a lot of shopping bags after a trip to Dallas.'], ['Two women are standing in a store with a baby in a blue stroller.', 'The women are inside.'], ['Five Asians have gathered for dinner at a table near a fire pit.', 'The five people are African american'], ['A group of men and women are having a discussion in a restaurant.', 'a crowd has a discussion in a hospital'], ['A woman wearing a red tank top is cutting a hamburger in half.', 'A man is making a salad.'], ['People talk near stereo equipment outdoors.', 'People are outdoors talking.'], ['A little girl, dressed in white and wearing safety goggles, is standing and smiling.', 'A girl is about to conduct an experiment.'], ['Two woman caught in a downpour in the middle of the city.', 'Two women are outside in the rain.'], ['A blond girl with orange and blue streaks on her face in a crowd.', 'A woman wears her teams colors on her face.'], ['A man in a dark pants lifts his leg while five girls wearing rollerskates gather near him.', 'An adult watches a group of maids clean the hotel.'], ['An elderly woman with a hat on is looking outside of her bus window.', 'A woman is on her way home.']]\n",
            "Cluster  2\n",
            "[[\"Two cowboys in a pen with a big spotted cow that has a rope around it's middle.\", 'There are two men.'], ['A brown horse jumps through its paddock.', 'The horse is green'], ['a large group of people in red uniforms are playing in a band.', 'The band is playing for a football game.'], ['Three blond girls and two blond women are playing with a jump rope in the dirt.', 'There are people competing in the jump rope championship.'], ['A group of five men in uniform are posing for the camera.', 'The men are naked.'], ['These people are having a wrestling match.', 'People are wearing boxing gloves.'], ['Two Formula race cars on an Eni sponsored racetrack.', 'The cars are in the middle of a race.'], ['a summer snowboarder going for an indy grab while jumping in the air.', 'The snowboarder performs a rail grind.'], ['A cheerleading team is posing in a pyramid in front of a crowd of watchers.', 'A team of cheerleaders are together.'], ['Several women running in a race, while the crowd looks on.', 'Several women running in a race'], ['Two men playing rugby collide.', 'The men are wearing grey uniforms.'], ['A man is preparing to tee off in golf, and there is a big crowd watching him.', 'The man is sweating from all the pressure.'], ['A group of dancers takes their bows.', 'The dancers end their routine and bow towards the crowd.'], ['Some young men racing on a beach.', 'The men are sleeping.'], ['A person is wearing a team uniform in blue and gold, seated on what is likely ice, with a goalie stick before him and the brand \"Reebok\" prominently displayed on uniform parts.', 'The hockey player fell down on the ice and lost control of his stick.'], [') (S (S (NP (PRP one)) (VP (VBZ is) (PP (IN in) (NP (DT a) (NN hole))))) (CC and) (S (NP (DT the) (JJ other) (CD two)) (VP (VBP are) (VP (VBG looking) (PP (IN at) (NP (NP (DT the) (NN man)) (VP (VBG standing) (PP (IN in) (NP (DT the) (NN hole)))))))))) (. .)))', '(ROOT (S (NP (CD Three) (NNS men)) (VP (VBP are) (VP (VBG standing) (PP (IN in) (NP (DT a) (NN hole))))) (. .)))'], ['A knight in full armor, including a protective, ventilated headpiece, rides his horse and carries his shield.', 'A knight in full armor, including a protective, ventilated headpiece, rides his horse'], ['Spectators watch a snowboarder in mid-flight amid a snowy landscape.', 'Spectators watch a snowboarder in mid-flight amid a snowy landscape do crazy tricks.'], ['Women play volleyball while two referees manage the game.', 'The women are hitting the volleyball across the net'], ['Three speed skaters racing down the ice rink.', 'The three speed skaters were watching tc'], ['One person is jumping on skis while others look on.', 'A person jumps on skis as a crowd watches.'], ['A man with metal legs posing after winning a race against other men with metal legs.', 'The men have metal legs.'], ['A female is throwing a javelin while a cameraman records her.', 'Woman throws spear at guy to get it on Youtube.'], ['Here is six gentlemen who are in a band, all are playing different instruments.', 'They play instuments'], ['A man is skiing in midair.', 'A man is yelling out in midair.'], ['Rollerblader in the air above a ramp.', 'Rollerblader off the ground above a ramp.'], [\"The spots on the giraffe's face are smaller than the ones on its neck.\", 'The giraffe does not have a neck'], ['Four skaters are competing in a high speed skating competition, and turning on the track.', 'Four people are racing.'], ['A man on a BMX bike performs a trick on a jump.', 'The man has a helmit on his head.'], ['Two basketball players jump in the air as one is about to make a slam dunk.', 'The players are athletic.'], ['A tennis match is in progress with ball chasers on the sidelines with an audience in the background.', 'A tennis match is going on in front of an audience.'], ['a basketball player in a white uniform is dribbling the basketball against a player in a black uniform.', 'People playing basketball.'], ['A woman in black and red softball gear is running along a sanded track while two women in yellow jerseys are in the middle of throwing a ball.', 'A woman races around a track to avoid getting in the way of the ball.'], ['Spectators in sunglasses at an event.', 'People are watching a sporting event.'], ['A man on a bike throws up dirt during a motor cross event.', 'A biker is winning an event.'], ['A man in a green top and gloves trots across a ball field.', 'A man is trotting across a football field.'], ['A crowd of people watch a martial arts demonstration.', 'A bunch of people watch people compete.'], ['A man is racing a camel as though it were a horse.', 'A man racing on a camel'], ['A man wearing a martial arts uniform is jumping through the air.', 'A man wearing a martial arts uniform and karate belt is jumping through the air'], ['Angry man yelling at a lady at walking away from him at a fair game.', 'Man yelling at a person.'], ['One person scoring a hit on another person while fencing.', 'Someone is winning a fencing match.'], ['Fencers compete for a point.', 'Cricketers are playing cricket for fun.'], ['A UW football player runs with the ball.', 'A football player running during a game.'], ['A group of dancers takes their bows.', 'The group is running away from home.'], ['Two male swimmers in black trunks jumping off a deck in a marina with boats in the background.', 'Nobody is jumping'], ['A man in a white, red, yellow, and black shirt and white pants arches his back to narrowly avoid a charging black bull in a bull fighting ring with red-painted sides while a number of spectators look on.', 'The man is wearing a cowboy hat.'], ['A man rides a bucking horse at a rodeo while the crowd snaps some photos.', 'The horse is grazing in the pasture.'], ['A football player wearing a number 23 white jersey tackles a football player wearing a red, number three jersey while fans cheer.', 'The player is wearing number 5.'], ['Two men are in a boxing match, with an audience watching.', 'A man is about to knock out his opponent.'], ['A woman in blue shorts and a red and white striped shirt throws a soccer ball out onto a green field with players on it.', 'There are a players on the field.'], ['A man on bike is jumping an obstacle with a crowd in the background.', 'A man on a bike.'], ['a lone person jumping through the air from one snowy mountain to another.', 'A person jumps in the air to see how high they can jump.'], ['A flag football player in a red jersey is being pursued by one in a blue jersey.', 'The player in blue has the ball.'], ['In a bowling alley, a man holding a green bowling ball looks ahead at the pins that he must knock down.', 'The man is playing in an professional bowling competition.'], ['A band of musicians performing for a rally.', 'A band hypes up a group of people before a big boxing match'], ['Bicycle rider airborne on a ramp.', 'The rider has a helmet on.'], ['Players from two teams tangle together in pursuit of a flying rugby ball.', 'One team practicing rugby.'], ['a male biker in a gray shirt crosses the finish line in celebration.', 'A biker finishes the race.'], ['Two teams, one wearing blue and white, the other in red and white, are playing football.', 'Two boys in white tackle a boy on the red team.']]\n",
            "Cluster  3\n",
            "[['A man is playing music with a trumpet.', 'A man playing music with a guitar.'], ['A man with a hard hat carries a tree branch.', 'The man with the hard hat had cut down a tree.'], ['An old bearded man holding a fruit.', 'An elderly bearded man holding a piece of fruit in his hand.'], ['A man in a blue coat looks at his feet in a bazaar.', 'A man is looking up at the ceiling in a grocery store.'], ['A man in a white t-shirt sits holds a newborn baby with a small hat on.', 'The baby is flying a plane.'], ['An obese man dressed in only shorts, parking a red motor scooter', 'a person on a scooter'], ['A shirtless man wearing light blue shorts and a baseball cap stands at the front of a boat.', 'The man is sailing.'], ['An outdoor cafe with people sitting while a man in white shirt is walking toward them.', 'A man is sitting at a table waiting for his date.'], ['An asian man giving a speech.', 'An asian man stands outside and gives a speech to a group'], ['A person walks through the snow wearing snowshoes with a fence in the background.', 'A man walks through heavy snow wearing green snowshoes in front of a wooden fence.'], ['A man in a black cap and blue shirt is looking for gold.', 'The man is a professional gold miner.'], ['A worker wearing a hazard cone on his head and holding a flare being photographed by two photographers as he leads a parade.', 'It is summer.'], ['A technician readying his equipment.', 'The man is outside.'], ['A man crashing on the waves.', 'a man swimming at a peaceful lake'], ['Two people wearing hats are standing in a field tending to a crop.', 'The two people are men.'], ['A man on Rollerblades grinding down a concrete handrail.', 'A man doing tricks on a handrail.'], ['A guy with glasses and a beard in a suit is surrounded by photographers.', 'A guy with glasses is and a beard is near cameras.'], ['Two men stop to talk near a sign outside.', 'Men are talking'], ['A guy jumps off of rocks into the water.', 'A guy jumps 20 feet into the water.'], ['A man in a yellow shirt wearing a tool belt examines something on a roof on a clear day.', 'The man is riding his motorcycle to the park.'], ['One man in a vest and tie plants a kiss on the cheek of another happy man.', 'The men are in outer space.'], ['One man wearing a green jacket, blue jeans, boots and a gray cowboy hat standing beside a barn watching the sun', 'A person stands outside.'], ['Bikers stopped on a road.', 'Men talking and riding bikes.'], ['A pensive young man of Indian descent, sitting on the ground resting against a tree, with other people engaged in conversation in the background.', 'A man is sitting and listening to the conversations.'], ['A shoe shiner waits for customers.', 'A person shining shoes.'], ['An unknown man works a grill in a kitchen wearing a coca cola shirt, there is much types of food to be seen.', 'A coke fan has a barbecue for his friends.'], ['A man wearing a plaid hat sits in a lawn chair reading a magazine', 'A woman wearing a plaid hat sits in a lawn chair reading a magazine'], ['A guy riding a skateboard in front of a graffiti wall.', 'A teenager is riding his board and looking at a wall of graffiti'], ['A man in all black carries a vegetable.', 'The man is sleeping.'], ['Two men are cooking in the kitchen using rice milk.', 'Two guys cook using some rice milk.'], ['There is a man with a moustache, cap and backpack standing by a bridge that running crosses water.', 'Some ducks eat bread.'], ['A man is sitting in the snow watching as a group of people are walking by.', 'A man in the snow watches a group of people walk by.'], ['A man in green walking down the beach while holding his shoes.', 'A gentleman in a green sweatsuit strolling along the shore, holding his tennis shoes.'], ['People stand and watch from the grassy hill as an airplane soars close overhead.', 'People are swimming in a lake.'], ['Two workers in uniform are standing next to some heavy machinery.', 'Two workers are standing by heavy machines'], ['a old man in a white shirt is eating a bun.', 'A man eats his lunch.'], ['A person in a yellow kayak is paddling through a river with snowy banks.', 'A person is in a race.'], ['Two men take photographs on either side of their car.', 'two men have sports cars'], ['A man with glasses and black jacket stands as he sculpts a strange-shaped sculpture.', 'A man is painting a picture.'], ['The two men calmly paddled the long boat in the sunset by the beach.', 'Some guys on a fishing trip.'], ['A man climbing a rock in a park.', 'A man pitching a tent in a park.'], ['a taxi cab with a mama mia ad on top of it', 'An automobile has an advertisement showing a popular play.'], ['An older man in an orange jacket is looking around.', 'An old man is looking around in the woods.'], ['A photographer is taking photos of flowers.', 'A photographer has decided to never take another photo.'], ['A mountain biker with a backpack crests a ridge.', 'The biker crested a ridge.'], ['This is an aged middle-eastern man looking to his right while wearing a white robe with gold embroidery.', 'Nobody is looking.'], ['A man in a jumpsuit and a headband is docking a boat.', 'A man is attempting to steal a boat.'], ['A man walks on the street.', 'A man is outdoors.'], ['Two older men wearing white kneading bread on a flour covered table.', 'Two men are baking.'], ['A bartender wearing a hat is pouring a drink.', 'The man is drinking a cocktail'], ['Man sitting on a bench in a wooded park, watching people walk past.', 'Man sitting on a bench in a wooded park, watching people walk past while eating his lunch.'], ['An individual playing a tuba.', 'a person is playing the tuba'], ['A man with a green backpack is walking through the rain behind two men, one of whom has an umbrella.', 'Three coworkers are walking through the rain on their way to have lunch.'], ['A man stands in front of a building wearing a hat and suit.', 'A woman is wearing a bathing suit.'], ['A man in a white hoodie relaxes in a chair by a fountain.', 'a turtle is eating a leaf'], ['The two man are fixing something.', 'Two men are arguing over a car accident they just had.'], ['Dark-skinned male in leather jacket sleeping.', 'An Asian man sleeps in a leather jacket.'], ['A construction worker in jeans is climbing scaffolding.', 'a worker climbs higher'], ['A young male dumps the extra water out of his small motorboat.', 'The man is outdoors.'], ['Two men working on a roof in yellow coats.', 'two guys work on the roof.'], ['Man at the beach builds a face out of sand.', 'a man making a sand sculpture.'], ['A man with white hair walking down the sidewalk.', 'An elderly man walks down the sidewalk'], ['A boat worker holding a rope.', 'The boat is parked in a driveway.'], ['A picture of a city with a sign welcoming travelers on a busy street.', 'A picture of a city is on a street'], ['Long-haired man napping on a park bench.', 'the man is taking a nap'], ['A man in a blue shirt gesticulates as he speaks to a uniformed official.', 'A man has a mouthfull of meatballs.'], ['A man on a red bicycle that is dragging a wagon behind it.', 'a woman holding a scruffy cat'], ['A man in a red robe and sandals is walking past a small food stand.', 'The man is barefoot.'], ['An artist is carving an intricate sculpture using a tree and an electric saw.', 'An artist is sculpting a tree.'], ['Two police officers question a seated man in front of a subway train.', 'The is more than one officer.'], ['A rickshaw puller in an Asian country smiling and making a \"thumbs up\" sign at the photographer.', 'He is towing goods for a street vendor.'], ['Several men are gathered around musical instruments and a microphone.', 'Men are gathered around musical instruments.'], ['A man in a suit is sitting at a desk and talking into a microphone.', 'A man is sleeping.'], ['A male in a black shirt near a large curved archway.', 'A man is standing near an arch.'], ['A guy with a red shirt and black apron on working standing with his hand in a shopping cart.', 'The man is wearing clothing.'], ['Four road workers planting a tree.', 'Four Workers are laying cement.'], ['A man with leg tattoos and boots using a shovel in the street.', 'A man is scraping his tattoos with a knife.'], ['Man trying to fix a train by leaning into the equipment box.', 'A man is leaning into a box.'], ['A person getting ready to buy merchandise.', 'A person getting ready to buy clothes.'], ['A man in a white tank top using a laptop sitting next to a tall pillar with a statue on top of it.', 'A man is working on his next book in a statue park.'], ['Workers in yellow safety vests plant a tree in a city walkway.', 'An urban tree planting is taking place.'], ['A man using a parachute controlled device going into a sunset background on a beautiful partly cloudy day.', 'A man is using a parachute on vacation.'], ['This man is relaxed and reading a book.', 'A man is standing on his head.'], ['A man floating in water reads a book.', 'A person is reading.'], ['An old man, wearing a black beret and a black and red jacket, rides a pony in a desolate mountain location.', 'An old man is riding a horse outside.'], ['A person stands alone at the top of the stairs.', 'The person is starting to walk down stairs.'], ['A man surfing on a white surfboard wearing specialized clothing.', 'Surfing on a surfboard requires waterproof clothing worn by people'], ['Three people are standing in the snow preparing an ice fishing boat.', 'A couple fishermen are fixing an ice fishing boat and getting it ready.'], [\"A man in a green shirt and tan cap leans against a railing in someone's kitchen.\", \"A man wearing a red shirt is in someone's bedroom.\"], ['A mannequin behind a blue car.', 'The mannequin is a prop for a horror movie.'], ['A man on a bicycle riding down the sidewalk and talking on the phone.', 'The bike has two wheels.'], ['A man with a red shirt is watching another man who is standing on top of a attached cart filled to the top.', 'A man is standing on a cart full of groceries.'], ['A group of workers are staring at a map and two men are pointing at the map.', 'The men are making a decision.'], ['A guy wearing a costume with a blue striped shirt.', 'A guy is going to a party.'], ['A smiling man holds a sign depicting a rainbow-colored elephant.', 'A person with a sign.'], ['A man sorts though his fish net on a makeshift frame.', 'A man is fishing with his fishing pole.'], ['A bulldozer is working inside a cordoned section of a street.', 'A bulldozer is getting ready to push a pile of snow.'], ['An african american cutting open crops.', 'An asian american cutting open crops'], ['A bartender wearing a hat is pouring a drink.', 'A person has a beverage.'], ['A construction worker in an orange vest walks.', 'A person is walking.'], ['A hiker standing on the shore of a lake.', 'There is a person standing near a lake'], ['A young man is sitting on a train platform waiting to clean shoes for money.', 'The man is sitting on platform number four.'], ['A man in a sweatshirt with a hat is looking over a bridge at a lake.', 'The man looks nice in his wedding suit.'], ['Most ride motorbikes in the area but one must be very careful.', 'Motorcycles are safe'], ['Three people sitting on a street corner looking tired.', 'Three old men are playing chess.'], ['African American man stands outside wearing a colorful orange and yellow shirt and jacket.', 'The man has no shirt on.'], ['a fountain sprays water as a biker sits in a chair talking on his cellphone, two others are present also talking on cellphones.', 'A bunch of people are playing hockey on a lake.'], ['A man holding a bag walking down a long staircase.', 'there is a bag'], ['A man in black clothing plays a guitar in front of a brick wall.', 'A man stands at the street corner holding up a sign for donations.'], ['A man in a white shirt and black pants looks on as other people are seated at tables beneath green umbrellas.', 'A man with white shirt and black pants looks on for people at table.'], ['Where is the rest of his racket?', 'A person is missing part of his racket.'], ['Several workers are building bleachers near a very large building.', \"There's new bleachers going in by our building.\"], ['The biker is riding through a grassy plain.', 'A biker is riding through a city.'], ['A motorcycle rider doing a wheelie.', 'There is a person on a vehicle.'], ['Two Black men are hoeing what seems to be a rough patch of dirt.', 'There are two men in this picture that are both working.'], ['A caucasian male in a green and white plaid shirt holding a microphone.', 'a male is about to perform a song'], ['Two men dressed in hula skirts on the back of a moving truck.', 'The men in hula skirts were dared to do so.'], ['A shirtless male rock climber, scaling a shear cliff with a body of water in the background.', 'A man is climbing a building.'], ['Two men in life jackets speed through the water in an orange motorboat.', 'Rescue crews speed through the water in a boat to try to save people from a sinking boat.'], ['A man sitting in a barber shop.', 'There is an individual waiting indoors.'], ['a young man playing a motorcycle video game.', 'The young man is driving a tractor.'], [\"An older bearded white man wearing a blue shirt and red jacket looks down at a hotdog he's holding.\", 'A man offers a hotdog to a waiting customer.'], ['Crowded street with a man holding a subway sign pointing customers to a subway sandwich shop.', 'A crowded street, and a man directing people to a sandwich shop using a sign.'], ['A rapper in a black outfit is on stage.', 'The man in the black is on a satge.'], ['A pilot in his uniform carrying luggage on his way to work.', 'A pilot in his uniform carrying stuff on his way to work.'], ['A man dressed in a black shirt and jean pants is cutting wood on a table to use for his half finished wooden fence around his yard.', 'The man started working on his fence last week.'], ['A man in a red shirt on the city street doing a fire trick.', 'The man is wearing a red shirt.'], ['A man in a blue hard hat and orange safety vest stands in an intersection while holding a flag.', 'The man wearing a blue hard hat and orange safety vest is the boss.'], ['A man in work clothes is holding a chain.', 'A man is holding a Barbie Doll.'], ['A policeman looks at an advertisement in a window', 'A policeman is looking at a broken window that a citizen is making a report about.'], ['A man on a steep incline wearing a white shirt is working on a roof, with lots of debris all around.', 'The man has a black shirt on.'], ['A man with sunglasses is playing the guitar.', 'The guitarist plays his favorite song.'], ['A man is tying his shoe lace.', 'A man is lacing up his shoes.'], ['A man in red and yellow garb sits upon a diving board.', 'There is a man on the diving board.'], ['A street vendor selling fruit drinks.', 'Someone is giving away drinks'], ['A man is hiking on a path, surrounded by trees, wearing a hat and carrying a water bottle.', 'The man is going for a hike and exploring nature.'], ['A man leans back while climbing a mountain tethered to a rope.', 'A mountain climber falls to his death.'], ['An olympic sand court being covered from the rain.', 'Rain on an object'], ['People are fishing and walking next to the water.', 'People are fishing and walking next to the water.'], ['a man wearing a backpack is walking down a wall with water on both sids.', 'A man is walking.'], ['A group of three men in white shirts stand near a police van while a man in a black jacket with a white stripe sits on the curb.', 'There is a police van on the street.'], ['People at a dock receiving and shipping out merchandise near a nice big white boat.', 'People are at a dock waiting to board a nice big white boat for a cruise.'], ['A man wearing an orange scarf is sitting on the grass with his legs crossed and his eyes closed', 'A man is meditating while sitting on the grass.'], ['A car is driving towards a green mountain.', 'A car is driving quickly.'], ['A man in an pilot uniform is walking down the sidewalk carrying luggage.', 'The clown is funny.'], ['A man in a blue shirt is holding a construction hat.', \"A man's hands are empty.\"], ['A decorated car headed down the street.', 'A car headed down the street.'], ['A man in uniform tries to find something with the help of a sniffing dog.', 'A woman walks by the man in uniform.'], ['a man speaking directly into a microphone', 'The man is rallying the troops before deployment during the military operation.'], ['The silhouette of a person jumping in the air during a sunset.', 'A person sitting on the ground in the middle of the day.'], ['A man with white shirt and blue jeans pushing a truck with a picture of a woman Edwards saying real colors never dye', 'A man with clothing on.'], ['A man in a blue shirt driving a Segway type vehicle.', 'A woman in a green shirt is sitting down.']]\n",
            "Cluster  4\n",
            "[['A big black dog chases a big brown dog with a green object in his mouth while another big brown dog tags behind.', 'The dogs have collars on.'], ['white bench looking out onto the ocean with dog.', 'A human looking out.'], ['A tan dog jumping up at a woman in a skirt and a black and tan dog walking away.', 'There are animals near a woman.'], ['A white dog with a yellow toy in his mouth runs through a nature trail towards the camera.', \"Someone's dog is lost and traveling alone.\"], ['A golden retriever is jumping off a wooden porch', 'A puppy leaps off the porch to play with a bone on the grass.'], ['A golden retriever puppy stands in front of two people looking over a railing.', 'The people are standing near a puppy.'], ['Two dogs playing or fighting in the snow.', 'The dogs are outside.'], ['A dog standing outside is looking at the camera.', 'A cat is standing alone.'], [\"A dog is licking a little girl's face.\", 'Her face is dry.'], ['Girl with two ducks on cliff overlooking the water.', 'A dog smells his butt.'], ['A brown dog is playing with a white fluffy stuffed animal.', 'A cat is napping.'], ['A brown dog playing in the sand.', 'A dog is playing in the sand.'], ['A large brown dog and a large black and white dog running together', 'the dogs are asleep'], ['A small white dog running on a pebble covered beach.', 'A seagull on the dock.'], ['Two dogs are running in a grassy field.', 'Two dogs are outside.'], ['A little white dog with long fur stands on his hind legs.', 'The dog likes standing on his hind legs.'], ['A brown dog is running in the sand.', 'A dark colored dog is sprinting across the ground.'], ['Three men are standing with a dog on a rock overlooking a mountainous scene.', 'Three men and a dog are standing on a rock overlook.'], ['A white dog is ready to catch a yellow ball flying through the air.', 'A dog is playing catch with his owner.'], ['A brown dogs walks near a green van and some junk.', 'A cat catches a mouse.'], ['A golden haired dog walking through shallow water', 'A yellow dog is in a body of water.'], ['A white dog with a black harness runs on a rocky shore.', 'A dog is outside.'], ['A black dog plays with a green object.', 'A dog is playing with something green.'], ['A black dog carrying an object out of the water.', 'There is a dog outdoors playing in the water'], ['A brown dog swims through water outdoors with a tennis ball in its mouth.', 'A dog is in the water.'], ['Three dogs running on a racetrack.', 'Three dogs are running to fetch a ball on the racetrack.'], ['The dog with all the comforts of home and yet still has no home.', 'The dog is lying in the grass.'], ['The dogs run and play with a red ball.', 'The dogs are playing catch.'], ['Three people sitting on the curb in an Asian city.', 'A group of dogs are riding in a car.'], ['A dog runs in a grassy field.', 'A dog running through a field.'], ['Two dogs, one brown one black with a yellow toy, black dog has mouth open and brown dog has the toy.', 'There are two dogs, one black and one brown.'], ['The white dog is being squirted in the face with a jet of water.', 'He is outside'], ['The black dog has a toy in its mouth and a person stands nearby.', 'The cat is playing with a toy.'], ['A skateboarder performing a kickflip over short stairs.', 'Woman walking a dog'], ['Fat man and dog are sitting in front of a statue.', 'There is an animal and a human sitting near a statue.'], ['A white furry dog jumping to catch a Frisbee.', 'The dog is a puppy.']]\n",
            "Cluster  5\n",
            "[['A mom and son having fun at the lake during winter.`', 'The mom and son are a family.'], ['Two young boys play with a puzzle in a classroom.', 'Two friends are playing a puzzle at home with there parents'], ['A child in medieval clothes points at something on a table.', 'The child is watching something.'], ['Two boys sand next to a drinking fountain in a park.', 'Two boys are waiting their turn for a drink.'], ['The boy is jumping in the air.', 'The girl jumps in air to keep from stepping on a pebble.'], ['A boy in a red poncho is reading while leaning on a pole.', 'A boy in a red poncho is reading The Hobbit while leaning on a pole.'], ['A woman and three children, holding hands with each other, are crossing the street.', 'The woman is the mother of the three children.'], ['A dark-skinned child blowing some bubbles using his mouth.', 'A child is blowing bubbles.'], ['A young boy and a young girl ride a bicycle down a street, with dirt and small trees around them.', 'Two adults are walking along the pier.'], ['Two young barefooted girls are climbing an old lava flow with their father and mother following close behind.', 'A family are climbing an old lava flow.'], ['A kid are playing with leaves by the sidewalk.', 'A child is playing by the street.'], ['A young child in a blue flowery dress walks along a sidewalk near a gated wall.', 'A young child in a black spandex body suit walks along a sidewalk near a gated wall.'], ['A young asian girl is sliding down a pole on outdoor playground equipment.', 'The girl is watching television.'], ['A young child is petting an animal.', 'A little boy is petting a dog.'], ['A youth standing nest to a metal fence with a black shirt on and a cigarette in their mouth.', 'child on a smoke break from working on the farm'], ['A child smiling for a picture.', 'A child posing for a picture.'], ['A boy wearing a bike helmet, jeans, and a striped shirt and a girl wearing a green shirt and jeans ride bikes with training wheels down a sidewalk.', 'Two dogs are sniffing bikes.'], ['A guy in an olive-green sweater and blue jeans is playing with a blond-haired toddler in a yard using toy golf clubs.', 'A man and child are playing outside.'], ['A group of children have fun in sack race.', 'some childrens standing in a park'], ['A young girl with curly hair with a white shirt with a skull and bones picture on it.', 'A young girl has curly hair.'], ['A young child wearing green shoes, red pants, a blue shirt, and a blue hat stands on top of a circle that is on a cracked piece of concrete.', 'A young child is not wearing a hat.'], ['A kid and man looking at animals from outside a fence.', 'Two people are looking at the same group of animals inside the fence.'], ['This stone sculptor gently shaded seems to decorate a garden but here a young boy dressed in a US flag decorated t-shirt enjoys climbing on it.', 'The t-shirt is moldy.'], ['A man in a striped shirt and two redheaded boys are posing for a picture outside.', 'A man in a solid white shirt and two black-haired boys pose for pictures inside.'], ['A young Caucasian boy climbs through a metal structure of stationary rings outside in a paved area overlooking a body of water.', 'A boy climbs through a structure of rings overlooking water.'], ['Two young children are playing with a bubble-maker.', 'The children are playing with bubbles.'], ['Two children are building something on the floor.', 'Two children are boys.'], ['A young girl is smiling in front of the camera at a park.', 'A young girl is smiling for the camera outside.'], ['A young child is playing with a yo-yo.', 'A young woman is singing.'], ['3 children on brick street, near a lamp post, trashcan and some adults.', '3 children are playing hopscotch with some adults.'], ['A girl in red standing on the sand while the girl in blue scratches her back while sitting on the sand.', 'the girls are at the beach'], ['A little boy is running down the aisle clutching a book.', 'Billy was running with his book clutched next to him.'], ['Two boys at play at a fun center, there are two women in the background laughing.', 'women in the background are happily laughing'], ['At night, a kid in a white shirt rides the rails on his skateboard.', 'The kid rides his skateboard at night because he is shy.'], ['A young boy wearing blue is standing next to a large red ball in a field.', 'A boy in blue is preparing to kick the red ball.'], ['A boy in a red plaid button-up shirt playing a guitar, with another boy playing an orange bass behind him, and another person playing a drum set.', 'Three boys are playing basketball.'], ['A young boy wearing a bathing suit and rash guard runs into the ocean as the waves bubble up on the shore.', 'A Surfer in a Wet Suit catches a Wave.'], ['A boy jumping to hit a tennis ball with his racket', 'A child is learning how to play tennis for the first time.'], ['children sitting on rock in the desert', 'children sitting on a rock at the park'], ['A boy is playing in a room full of balls.', 'A boy is playing with a bike.'], ['Some children are playing in a slum.', 'A slum has children playing in it.'], ['A boy in orange swim trunks stands on a diving board above a pool.', 'horse looks at bull'], ['Two children on a beach are playing in the sand as the tide comes in.', 'Children on a beach are playing in the sand.'], ['People with strollers walking on a bridge.', 'There are parents with strollers walking on a bridge.'], ['A child dressed in blue is holding a blue bucket and handing a shovel to the other child, who is wearing a green jacket and yellow boots.', 'Two boys play in the sand together at the playground.'], ['There is three small children playing and some adults are sitting on the benches.', 'The adults are sitting down.'], ['People are gathered at an event in a sandy area.', 'A group of children on the beach.'], ['Children in a green classroom are raising their hands.', 'Children are raising their hands in a green classroom to protest the ugly color.'], [\"A little boy trying to brush a woman's hair.\", \"A little boy is trying to brush a woman's hair.\"], ['Two boys sand next to a drinking fountain in a park.', 'Two brothers stand besides a drinking fountain on a bright day'], ['A young girl rides a unicycle next to another riding a scooter on a busy street.', 'A young boy rides a unicycle next to another riding a scooter on a busy street.'], ['A little boy in blue runs through a flock of pigeons standing on the ground.', 'A boy dressed in blue runs through a flock of pigeons.'], ['A young girl and an older man are checking out at the food store.', 'The father took his daughter to buy groceries.'], ['Two boys dressed up at a school.', 'The boys are at the dentist office.'], ['Young girls in bathing suits playing in the knee deep water beyond the blue railing.', 'The water is twenty feet deep.'], ['A young kid smiling, looking joyous.', 'A young child is happy.'], ['A young girl in a blue shirt is walking in the sidewalk and holding up a pink sign that says, \"The Rescue.\"', 'A girl walking on the sidewalk.'], ['A young child in a yellow shirt and shorts frolics at a park, with birds in the background.', 'The child is in bed asleep.'], ['A young toddler wearing pink sandals is walking on hopscotch numbers.', 'A baby walks on the ground.'], ['Two young barefooted girls are climbing an old lava flow with their father and mother following close behind.', 'A family is climbing some rocks together.'], ['A group of children dance and play instruments under colored lights.', 'A group of children are sitting quietly listening to music.'], ['Children stand and wait for the train.', 'Some children are sleeping at a bus stop.'], ['A little boy is hiding underneath a table on the street that is displaying fruit.', 'A little boy driving a car.'], ['A group of multi-cultural kids are excited by what they are watching.', 'A group of kids fighting is about to get broken up by a cop.'], ['A boy jumping to hit a tennis ball with his racket', 'A girl picks up tennis balls in a field.'], ['A sad little boy sits in a car seat.', 'A crying baby is in a carrier seat.'], ['Fair haired child peers into the top of an orange road traffic cone.', 'An angry child peers into the top of an orange road traffic cone.'], ['A young girl wearing a pink floral outfit walks down the sidewalk.', 'A young girl is wearing tennis shoes'], ['Four young boys talking to a man.', 'Four boys eating lunch inside.'], ['A young boy swings a bat at a large baseball.', 'The young boy is playing with a bat.'], ['A boy flying a red and white kite.', 'A boy is flying a blue and black kite.'], ['Young boy jumping in the air with his knees bent and arms spread.', 'A child jumps and with his arms spread.'], ['A closeup of a young girl with a pink shirt laying on grass.', 'The child is playing on the swings.'], ['A young boy, in a white jersey, has kicked a green and white soccer ball.', 'A boy is sitting on the bench watching the soccer game.'], ['A child stands in the snow.', 'Two goldfish are riding bikes in a giant pile of mashed potatoes.'], ['A little girl wearing a blue sweater holding the string out on a pink yo-yo.', 'A little girl is skydiving'], ['A baby in campflauge crawls on a clean hardwood floor.', 'A baby can crawl mostly on clean hardwood floor.'], ['Two young children wearing green fleece, surrounded by toys.', 'The children are under ten years old.'], ['A group of young boys making silly faces.', 'Children are being silly'], ['Smiling toddler dressed in a hoodie and a brown paper cape is standing on a dirt hill.', 'Smiling toddler is dressed in a homemade Halloween outfit.'], ['A child in a gray coat kicking a soccer ball.', 'A child is getting exercise.'], ['A boy wearing a black wetsuit stands on a crowded beach.', 'A boy is in the park wearing a business suit.'], ['A toddler holds a rubber chicken suspended in air', 'A child is playing with a rubber chicken outside.'], ['Three boys in hooded sweatshirts standing and looking at camera.', 'Three young school friends pose.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYagm244VESO"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "Training is done only for the top layers to perform \"feature extraction\",\n",
        "which will allow the model to use the representations of the pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY9AL5FnDkXG",
        "outputId": "b374fda5-4bf0-48cb-8b49-8b79e1f9e805"
      },
      "source": [
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=valid_data,\n",
        "    epochs=epochs,\n",
        "    use_multiprocessing=True,\n",
        "    workers=-1\n",
        "\n",
        ")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   6/3121 [..............................] - ETA: 31:59 - loss: 1.2129 - acc: 0.2969"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   8/3121 [..............................] - ETA: 32:02 - loss: 1.2640 - acc: 0.2812"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  26/3121 [..............................] - ETA: 31:51 - loss: 1.1564 - acc: 0.3269"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  44/3121 [..............................] - ETA: 31:39 - loss: 1.1311 - acc: 0.3558"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  90/3121 [..............................] - ETA: 31:09 - loss: 1.0941 - acc: 0.3969"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 114/3121 [>.............................] - ETA: 30:52 - loss: 1.0851 - acc: 0.4073"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 264/3121 [=>............................] - ETA: 29:18 - loss: 1.0023 - acc: 0.4950"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 350/3121 [==>...........................] - ETA: 28:24 - loss: 0.9620 - acc: 0.5286"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 355/3121 [==>...........................] - ETA: 28:21 - loss: 0.9595 - acc: 0.5304"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 405/3121 [==>...........................] - ETA: 27:50 - loss: 0.9397 - acc: 0.5451"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 429/3121 [===>..........................] - ETA: 27:35 - loss: 0.9328 - acc: 0.5508"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 430/3121 [===>..........................] - ETA: 27:34 - loss: 0.9327 - acc: 0.5508"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 459/3121 [===>..........................] - ETA: 27:16 - loss: 0.9245 - acc: 0.5566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 481/3121 [===>..........................] - ETA: 27:02 - loss: 0.9163 - acc: 0.5619"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 532/3121 [====>.........................] - ETA: 26:31 - loss: 0.9043 - acc: 0.5712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 563/3121 [====>.........................] - ETA: 26:11 - loss: 0.8958 - acc: 0.5770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 596/3121 [====>.........................] - ETA: 25:51 - loss: 0.8886 - acc: 0.5825"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 659/3121 [=====>........................] - ETA: 25:12 - loss: 0.8741 - acc: 0.5917"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 715/3121 [=====>........................] - ETA: 24:37 - loss: 0.8649 - acc: 0.5979"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 730/3121 [======>.......................] - ETA: 24:28 - loss: 0.8614 - acc: 0.5999"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 825/3121 [======>.......................] - ETA: 23:30 - loss: 0.8454 - acc: 0.6104"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 834/3121 [=======>......................] - ETA: 23:24 - loss: 0.8446 - acc: 0.6111"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 849/3121 [=======>......................] - ETA: 23:15 - loss: 0.8419 - acc: 0.6127"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 850/3121 [=======>......................] - ETA: 23:14 - loss: 0.8417 - acc: 0.6128"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 907/3121 [=======>......................] - ETA: 22:39 - loss: 0.8335 - acc: 0.6183"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 958/3121 [========>.....................] - ETA: 22:08 - loss: 0.8267 - acc: 0.6235"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 994/3121 [========>.....................] - ETA: 21:45 - loss: 0.8225 - acc: 0.6261"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 999/3121 [========>.....................] - ETA: 21:42 - loss: 0.8216 - acc: 0.6267"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1031/3121 [========>.....................] - ETA: 21:23 - loss: 0.8163 - acc: 0.6300"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1305/3121 [===========>..................] - ETA: 18:35 - loss: 0.7865 - acc: 0.6479"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1332/3121 [===========>..................] - ETA: 18:18 - loss: 0.7836 - acc: 0.6500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1348/3121 [===========>..................] - ETA: 18:08 - loss: 0.7822 - acc: 0.6509"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1398/3121 [============>.................] - ETA: 17:37 - loss: 0.7776 - acc: 0.6538"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1435/3121 [============>.................] - ETA: 17:15 - loss: 0.7746 - acc: 0.6559"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1473/3121 [=============>................] - ETA: 16:51 - loss: 0.7718 - acc: 0.6578"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1511/3121 [=============>................] - ETA: 16:28 - loss: 0.7691 - acc: 0.6598"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1763/3121 [===============>..............] - ETA: 13:53 - loss: 0.7512 - acc: 0.6699"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1766/3121 [===============>..............] - ETA: 13:51 - loss: 0.7510 - acc: 0.6700"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1821/3121 [================>.............] - ETA: 13:17 - loss: 0.7482 - acc: 0.6716"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1888/3121 [=================>............] - ETA: 12:36 - loss: 0.7445 - acc: 0.6736"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1940/3121 [=================>............] - ETA: 12:04 - loss: 0.7418 - acc: 0.6751"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1942/3121 [=================>............] - ETA: 12:03 - loss: 0.7417 - acc: 0.6752"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1951/3121 [=================>............] - ETA: 11:57 - loss: 0.7412 - acc: 0.6754"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1992/3121 [==================>...........] - ETA: 11:32 - loss: 0.7389 - acc: 0.6768"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2047/3121 [==================>...........] - ETA: 10:58 - loss: 0.7364 - acc: 0.6786"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2055/3121 [==================>...........] - ETA: 10:53 - loss: 0.7360 - acc: 0.6788"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2119/3121 [===================>..........] - ETA: 10:14 - loss: 0.7335 - acc: 0.6806"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2127/3121 [===================>..........] - ETA: 10:09 - loss: 0.7328 - acc: 0.6809"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2130/3121 [===================>..........] - ETA: 10:07 - loss: 0.7328 - acc: 0.6808"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2178/3121 [===================>..........] - ETA: 9:38 - loss: 0.7305 - acc: 0.6821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2188/3121 [====================>.........] - ETA: 9:32 - loss: 0.7301 - acc: 0.6823"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2263/3121 [====================>.........] - ETA: 8:46 - loss: 0.7266 - acc: 0.6843"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2284/3121 [====================>.........] - ETA: 8:33 - loss: 0.7251 - acc: 0.6851"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2291/3121 [=====================>........] - ETA: 8:29 - loss: 0.7251 - acc: 0.6852"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2301/3121 [=====================>........] - ETA: 8:23 - loss: 0.7248 - acc: 0.6852"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2337/3121 [=====================>........] - ETA: 8:00 - loss: 0.7234 - acc: 0.6860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2362/3121 [=====================>........] - ETA: 7:45 - loss: 0.7224 - acc: 0.6865"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2414/3121 [======================>.......] - ETA: 7:13 - loss: 0.7204 - acc: 0.6877"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2430/3121 [======================>.......] - ETA: 7:03 - loss: 0.7201 - acc: 0.6880"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2452/3121 [======================>.......] - ETA: 6:50 - loss: 0.7193 - acc: 0.6884"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2477/3121 [======================>.......] - ETA: 6:35 - loss: 0.7184 - acc: 0.6888"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2481/3121 [======================>.......] - ETA: 6:32 - loss: 0.7183 - acc: 0.6889"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2589/3121 [=======================>......] - ETA: 5:26 - loss: 0.7141 - acc: 0.6916"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2591/3121 [=======================>......] - ETA: 5:25 - loss: 0.7140 - acc: 0.6917"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2650/3121 [========================>.....] - ETA: 4:48 - loss: 0.7123 - acc: 0.6926"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2795/3121 [=========================>....] - ETA: 3:19 - loss: 0.7082 - acc: 0.6947"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2809/3121 [==========================>...] - ETA: 3:11 - loss: 0.7079 - acc: 0.6949"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2822/3121 [==========================>...] - ETA: 3:03 - loss: 0.7078 - acc: 0.6950"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2836/3121 [==========================>...] - ETA: 2:54 - loss: 0.7074 - acc: 0.6953"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2842/3121 [==========================>...] - ETA: 2:51 - loss: 0.7071 - acc: 0.6954"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2849/3121 [==========================>...] - ETA: 2:46 - loss: 0.7070 - acc: 0.6955"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2901/3121 [==========================>...] - ETA: 2:14 - loss: 0.7053 - acc: 0.6964"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2912/3121 [==========================>...] - ETA: 2:08 - loss: 0.7050 - acc: 0.6966"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2972/3121 [===========================>..] - ETA: 1:31 - loss: 0.7035 - acc: 0.6975"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3034/3121 [============================>.] - ETA: 53s - loss: 0.7012 - acc: 0.6989"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3035/3121 [============================>.] - ETA: 52s - loss: 0.7012 - acc: 0.6989"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3066/3121 [============================>.] - ETA: 33s - loss: 0.7005 - acc: 0.6993"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3105/3121 [============================>.] - ETA: 9s - loss: 0.6994 - acc: 0.6999 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3121/3121 [==============================] - ETA: 0s - loss: 0.6988 - acc: 0.7003"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3121/3121 [==============================] - 2108s 669ms/step - loss: 0.6988 - acc: 0.7003 - val_loss: 0.5230 - val_acc: 0.7895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwz77KgPVESP"
      },
      "source": [
        "## Fine-tuning\n",
        "\n",
        "This step must only be performed after the feature extraction model has\n",
        "been trained to convergence on the new data.\n",
        "\n",
        "This is an optional last step where `bert_model` is unfreezed and retrained\n",
        "with a very low learning rate. This can deliver meaningful improvement by\n",
        "incrementally adapting the pretrained features to the new data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO13jUpYDpU5",
        "outputId": "f70f0a2a-cd8d-4e4b-ab52-42c403c6c660"
      },
      "source": [
        "# Unfreeze the bert_model.\n",
        "bert_model.trainable = True\n",
        "# Recompile the model to make the change effective.\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_masks (InputLayer)    [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "token_type_ids (InputLayer)     [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n",
            "                                                                 attention_masks[0][0]            \n",
            "                                                                 token_type_ids[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 128, 128)     426496      tf_bert_model[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 128)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 128)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           global_average_pooling1d[0][0]   \n",
            "                                                                 global_max_pooling1d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 256)          0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 3)            771         dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 109,909,507\n",
            "Trainable params: 109,909,507\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM1PgYyIDvPJ",
        "outputId": "1b4ff649-ce6d-4f24-e6e0-2bf0c0886284"
      },
      "source": [
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=valid_data,\n",
        "    epochs=epochs,\n",
        "    use_multiprocessing=True,\n",
        "    workers=-1,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "  11/3121 [..............................] - ETA: 1:18:27 - loss: 0.6115 - accuracy: 0.7528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  42/3121 [..............................] - ETA: 1:17:57 - loss: 0.6124 - accuracy: 0.7522"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  48/3121 [..............................] - ETA: 1:17:50 - loss: 0.6071 - accuracy: 0.7533"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  59/3121 [..............................] - ETA: 1:17:31 - loss: 0.5870 - accuracy: 0.7638"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  74/3121 [..............................] - ETA: 1:17:09 - loss: 0.5765 - accuracy: 0.7669"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  90/3121 [..............................] - ETA: 1:16:44 - loss: 0.5622 - accuracy: 0.7712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 121/3121 [>.............................] - ETA: 1:15:55 - loss: 0.5474 - accuracy: 0.7745"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 162/3121 [>.............................] - ETA: 1:14:52 - loss: 0.5435 - accuracy: 0.7768"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 190/3121 [>.............................] - ETA: 1:14:08 - loss: 0.5387 - accuracy: 0.7794"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 198/3121 [>.............................] - ETA: 1:13:56 - loss: 0.5407 - accuracy: 0.7792"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 224/3121 [=>............................] - ETA: 1:13:17 - loss: 0.5382 - accuracy: 0.7821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 339/3121 [==>...........................] - ETA: 1:10:19 - loss: 0.5289 - accuracy: 0.7877"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 502/3121 [===>..........................] - ETA: 1:06:13 - loss: 0.5185 - accuracy: 0.7926"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 538/3121 [====>.........................] - ETA: 1:05:18 - loss: 0.5194 - accuracy: 0.7925"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 571/3121 [====>.........................] - ETA: 1:04:28 - loss: 0.5204 - accuracy: 0.7924"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 681/3121 [=====>........................] - ETA: 1:01:40 - loss: 0.5168 - accuracy: 0.7952"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 692/3121 [=====>........................] - ETA: 1:01:23 - loss: 0.5169 - accuracy: 0.7953"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 726/3121 [=====>........................] - ETA: 1:00:31 - loss: 0.5140 - accuracy: 0.7968"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 821/3121 [======>.......................] - ETA: 58:05 - loss: 0.5122 - accuracy: 0.7971"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 834/3121 [=======>......................] - ETA: 57:45 - loss: 0.5112 - accuracy: 0.7975"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 854/3121 [=======>......................] - ETA: 57:15 - loss: 0.5107 - accuracy: 0.7977"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 865/3121 [=======>......................] - ETA: 56:58 - loss: 0.5105 - accuracy: 0.7979"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 890/3121 [=======>......................] - ETA: 56:20 - loss: 0.5101 - accuracy: 0.7982"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 923/3121 [=======>......................] - ETA: 55:30 - loss: 0.5081 - accuracy: 0.7993"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 976/3121 [========>.....................] - ETA: 54:09 - loss: 0.5071 - accuracy: 0.7997"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 982/3121 [========>.....................] - ETA: 54:00 - loss: 0.5069 - accuracy: 0.7998"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 988/3121 [========>.....................] - ETA: 53:51 - loss: 0.5071 - accuracy: 0.7997"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1067/3121 [=========>....................] - ETA: 51:50 - loss: 0.5053 - accuracy: 0.8010"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1082/3121 [=========>....................] - ETA: 51:28 - loss: 0.5043 - accuracy: 0.8015"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1181/3121 [==========>...................] - ETA: 48:57 - loss: 0.5017 - accuracy: 0.8033"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1246/3121 [==========>...................] - ETA: 47:18 - loss: 0.4998 - accuracy: 0.8040"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1256/3121 [===========>..................] - ETA: 47:03 - loss: 0.4999 - accuracy: 0.8039"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1270/3121 [===========>..................] - ETA: 46:42 - loss: 0.4997 - accuracy: 0.8041"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1277/3121 [===========>..................] - ETA: 46:31 - loss: 0.4995 - accuracy: 0.8043"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1295/3121 [===========>..................] - ETA: 46:04 - loss: 0.4989 - accuracy: 0.8046"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1335/3121 [===========>..................] - ETA: 45:03 - loss: 0.4981 - accuracy: 0.8047"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1341/3121 [===========>..................] - ETA: 44:54 - loss: 0.4982 - accuracy: 0.8047"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1353/3121 [============>.................] - ETA: 44:36 - loss: 0.4974 - accuracy: 0.8050"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1379/3121 [============>.................] - ETA: 43:56 - loss: 0.4966 - accuracy: 0.8054"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1455/3121 [============>.................] - ETA: 42:01 - loss: 0.4955 - accuracy: 0.8059"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1456/3121 [============>.................] - ETA: 42:00 - loss: 0.4955 - accuracy: 0.8058"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1472/3121 [=============>................] - ETA: 41:35 - loss: 0.4947 - accuracy: 0.8062"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1519/3121 [=============>................] - ETA: 40:24 - loss: 0.4938 - accuracy: 0.8066"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1564/3121 [==============>...............] - ETA: 39:16 - loss: 0.4930 - accuracy: 0.8072"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1574/3121 [==============>...............] - ETA: 39:01 - loss: 0.4929 - accuracy: 0.8073"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1617/3121 [==============>...............] - ETA: 37:55 - loss: 0.4923 - accuracy: 0.8077"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1621/3121 [==============>...............] - ETA: 37:49 - loss: 0.4922 - accuracy: 0.8078"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1698/3121 [===============>..............] - ETA: 35:53 - loss: 0.4914 - accuracy: 0.8082"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1862/3121 [================>.............] - ETA: 31:44 - loss: 0.4890 - accuracy: 0.8095"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1868/3121 [================>.............] - ETA: 31:35 - loss: 0.4887 - accuracy: 0.8096"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1957/3121 [=================>............] - ETA: 29:20 - loss: 0.4862 - accuracy: 0.8106"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1990/3121 [==================>...........] - ETA: 28:30 - loss: 0.4856 - accuracy: 0.8109"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1993/3121 [==================>...........] - ETA: 28:26 - loss: 0.4855 - accuracy: 0.8110"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2031/3121 [==================>...........] - ETA: 27:28 - loss: 0.4848 - accuracy: 0.8111"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2051/3121 [==================>...........] - ETA: 26:58 - loss: 0.4845 - accuracy: 0.8113"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2105/3121 [===================>..........] - ETA: 25:36 - loss: 0.4838 - accuracy: 0.8117"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2131/3121 [===================>..........] - ETA: 24:57 - loss: 0.4840 - accuracy: 0.8117"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2172/3121 [===================>..........] - ETA: 23:55 - loss: 0.4834 - accuracy: 0.8119"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2204/3121 [====================>.........] - ETA: 23:06 - loss: 0.4825 - accuracy: 0.8124"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2227/3121 [====================>.........] - ETA: 22:32 - loss: 0.4820 - accuracy: 0.8124"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2230/3121 [====================>.........] - ETA: 22:27 - loss: 0.4819 - accuracy: 0.8124"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2265/3121 [====================>.........] - ETA: 21:34 - loss: 0.4823 - accuracy: 0.8122"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2290/3121 [=====================>........] - ETA: 20:56 - loss: 0.4820 - accuracy: 0.8124"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2363/3121 [=====================>........] - ETA: 19:06 - loss: 0.4808 - accuracy: 0.8128"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2374/3121 [=====================>........] - ETA: 18:49 - loss: 0.4807 - accuracy: 0.8129"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2408/3121 [======================>.......] - ETA: 17:58 - loss: 0.4800 - accuracy: 0.8133"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2429/3121 [======================>.......] - ETA: 17:26 - loss: 0.4796 - accuracy: 0.8134"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2437/3121 [======================>.......] - ETA: 17:14 - loss: 0.4795 - accuracy: 0.8135"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2457/3121 [======================>.......] - ETA: 16:44 - loss: 0.4790 - accuracy: 0.8136"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2468/3121 [======================>.......] - ETA: 16:27 - loss: 0.4786 - accuracy: 0.8138"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2524/3121 [=======================>......] - ETA: 15:02 - loss: 0.4777 - accuracy: 0.8143"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2566/3121 [=======================>......] - ETA: 13:59 - loss: 0.4774 - accuracy: 0.8143"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2739/3121 [=========================>....] - ETA: 9:37 - loss: 0.4742 - accuracy: 0.8155"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2752/3121 [=========================>....] - ETA: 9:18 - loss: 0.4741 - accuracy: 0.8155"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2792/3121 [=========================>....] - ETA: 8:17 - loss: 0.4733 - accuracy: 0.8160"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2794/3121 [=========================>....] - ETA: 8:14 - loss: 0.4733 - accuracy: 0.8160"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2844/3121 [==========================>...] - ETA: 6:58 - loss: 0.4732 - accuracy: 0.8163"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2903/3121 [==========================>...] - ETA: 5:29 - loss: 0.4723 - accuracy: 0.8167"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3063/3121 [============================>.] - ETA: 1:27 - loss: 0.4707 - accuracy: 0.8173"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3121/3121 [==============================] - ETA: 0s - loss: 0.4705 - accuracy: 0.8174"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3121/3121 [==============================] - 4908s 2s/step - loss: 0.4705 - accuracy: 0.8174 - val_loss: 0.3637 - val_accuracy: 0.8635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/2\n",
            "  12/3121 [..............................] - ETA: 1:18:12 - loss: 0.3507 - accuracy: 0.8724"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100/3121 [..............................] - ETA: 1:16:07 - loss: 0.3352 - accuracy: 0.8734"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 167/3121 [>.............................] - ETA: 1:14:36 - loss: 0.3394 - accuracy: 0.8752"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 184/3121 [>.............................] - ETA: 1:14:12 - loss: 0.3389 - accuracy: 0.8748"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 186/3121 [>.............................] - ETA: 1:14:09 - loss: 0.3400 - accuracy: 0.8742"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 224/3121 [=>............................] - ETA: 1:13:12 - loss: 0.3457 - accuracy: 0.8721"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 249/3121 [=>............................] - ETA: 1:12:36 - loss: 0.3469 - accuracy: 0.8715"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 288/3121 [=>............................] - ETA: 1:11:37 - loss: 0.3519 - accuracy: 0.8687"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 318/3121 [==>...........................] - ETA: 1:10:52 - loss: 0.3552 - accuracy: 0.8681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 433/3121 [===>..........................] - ETA: 1:07:59 - loss: 0.3540 - accuracy: 0.8685"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 453/3121 [===>..........................] - ETA: 1:07:29 - loss: 0.3544 - accuracy: 0.8675"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 509/3121 [===>..........................] - ETA: 1:06:05 - loss: 0.3527 - accuracy: 0.8680"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 534/3121 [====>.........................] - ETA: 1:05:27 - loss: 0.3551 - accuracy: 0.8670"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 546/3121 [====>.........................] - ETA: 1:05:09 - loss: 0.3541 - accuracy: 0.8677"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 599/3121 [====>.........................] - ETA: 1:03:48 - loss: 0.3531 - accuracy: 0.8680"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 601/3121 [====>.........................] - ETA: 1:03:45 - loss: 0.3531 - accuracy: 0.8680"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 611/3121 [====>.........................] - ETA: 1:03:30 - loss: 0.3524 - accuracy: 0.8681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 612/3121 [====>.........................] - ETA: 1:03:28 - loss: 0.3525 - accuracy: 0.8681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 661/3121 [=====>........................] - ETA: 1:02:12 - loss: 0.3534 - accuracy: 0.8681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 670/3121 [=====>........................] - ETA: 1:01:58 - loss: 0.3529 - accuracy: 0.8683"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 685/3121 [=====>........................] - ETA: 1:01:35 - loss: 0.3531 - accuracy: 0.8683"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 719/3121 [=====>........................] - ETA: 1:00:43 - loss: 0.3525 - accuracy: 0.8689"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 739/3121 [======>.......................] - ETA: 1:00:12 - loss: 0.3521 - accuracy: 0.8690"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 841/3121 [=======>......................] - ETA: 57:35 - loss: 0.3522 - accuracy: 0.8691"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 881/3121 [=======>......................] - ETA: 56:34 - loss: 0.3509 - accuracy: 0.8694"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 890/3121 [=======>......................] - ETA: 56:20 - loss: 0.3509 - accuracy: 0.8693"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 961/3121 [========>.....................] - ETA: 54:32 - loss: 0.3515 - accuracy: 0.8697"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 979/3121 [========>.....................] - ETA: 54:04 - loss: 0.3523 - accuracy: 0.8694"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1012/3121 [========>.....................] - ETA: 53:14 - loss: 0.3526 - accuracy: 0.8693"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1034/3121 [========>.....................] - ETA: 52:40 - loss: 0.3524 - accuracy: 0.8695"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1140/3121 [=========>....................] - ETA: 49:59 - loss: 0.3548 - accuracy: 0.8688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1159/3121 [==========>...................] - ETA: 49:30 - loss: 0.3545 - accuracy: 0.8689"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1166/3121 [==========>...................] - ETA: 49:20 - loss: 0.3547 - accuracy: 0.8688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1210/3121 [==========>...................] - ETA: 48:13 - loss: 0.3553 - accuracy: 0.8683"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1246/3121 [==========>...................] - ETA: 47:19 - loss: 0.3554 - accuracy: 0.8684"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1319/3121 [===========>..................] - ETA: 45:29 - loss: 0.3551 - accuracy: 0.8685"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1391/3121 [============>.................] - ETA: 43:40 - loss: 0.3552 - accuracy: 0.8683"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1394/3121 [============>.................] - ETA: 43:36 - loss: 0.3552 - accuracy: 0.8683"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1412/3121 [============>.................] - ETA: 43:09 - loss: 0.3551 - accuracy: 0.8682"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1425/3121 [============>.................] - ETA: 42:49 - loss: 0.3549 - accuracy: 0.8682"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1440/3121 [============>.................] - ETA: 42:26 - loss: 0.3550 - accuracy: 0.8683"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyS99YINDxjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9af4bcfa-83a1-4f86-94d9-c48c317e8306"
      },
      "source": [
        "test_data = BertSemanticDataGenerator(\n",
        "    test_df[[\"sentence1\", \"sentence2\"]].values.astype(\"str\"),\n",
        "    y_test,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        ")\n",
        "model.evaluate(test_data, verbose=1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 69/312 [=====>........................] - ETA: 2:15 - loss: 0.5437 - acc: 0.7894"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 82/312 [======>.......................] - ETA: 2:07 - loss: 0.5425 - acc: 0.7858"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "312/312 [==============================] - 173s 555ms/step - loss: 0.5404 - acc: 0.7858\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5403997898101807, 0.7857571840286255]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwORAuZyE0yK"
      },
      "source": [
        "##**Load and Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1JQV2QZCVaf",
        "outputId": "69c163f5-45ce-4164-99c6-d0781dce1f2c"
      },
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = bert_model.module if hasattr(model, 'module') else bert_model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "train_data.tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "#torch.save(model.state_dict(), os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to ./model_save/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/tokenizer_config.json',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/vocab.txt',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCG445OKCWq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5abd509-8cb1-4658-9584-2e34216c5366"
      },
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "drive.mount('MyDrive')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at MyDrive; to attempt to forcibly remount, call drive.mount(\"MyDrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHMB1wrcCjBR"
      },
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "!cp -r ./model_save/ \"./MY FILES\""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuSljJUFCrTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf7d7e2-5550-4cd0-9300-a24a76fa1bb9"
      },
      "source": [
        "model1 = transformers.TFBertModel.from_pretrained(output_dir)\n",
        "tokenizer1 = BertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "#model.to(device)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertModel.\n",
            "\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at ./model_save/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0xtidYkVESS"
      },
      "source": [
        "## Inference on custom sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ8a1mO7DzR1"
      },
      "source": [
        "\n",
        "def check_similarity(sentence1, sentence2):\n",
        "    sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n",
        "    test_data = BertSemanticDataGenerator(\n",
        "        sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n",
        "    )\n",
        "\n",
        "    proba = model.predict(test_data)[0]\n",
        "    idx = np.argmax(proba)\n",
        "    proba = f\"{proba[idx]: .2f}%\"\n",
        "    pred = labels[idx]\n",
        "    return pred, proba\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-Q8zTClD4o6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb98d32-91d7-474d-d06f-2ab983e22553"
      },
      "source": [
        "sentence1 = \"Two women are observing something together.\"\n",
        "sentence2 = \"Two women are standing with their eyes closed.\"\n",
        "check_similarity(sentence1, sentence2)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('entailment', ' 0.56%')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVWoSjvwD-RP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6daefcf5-36e5-4d76-a5d0-9beaa3ca2dd2"
      },
      "source": [
        "sentence1 = \"A smiling costumed woman is holding an umbrella\"\n",
        "sentence2 = \"A happy woman in a fairy costume holds an umbrella\"\n",
        "check_similarity(sentence1, sentence2)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('neutral', ' 0.60%')"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Je7LEXEBh_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b9b5bfa-387b-4403-df67-f9ee7e6c9411"
      },
      "source": [
        "sentence1 = \"A soccer game with multiple males playing\"\n",
        "sentence2 = \"Some men are playing a sport\"\n",
        "check_similarity(sentence1, sentence2)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('entailment', ' 0.94%')"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRLtlL_rPbrx"
      },
      "source": [
        "##**Semantic Search with S-bert**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "gF029MaUOvpR",
        "outputId": "93be0067-d583-4d20-cebe-5c6368027516"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similarity</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>Two male clowns, one in a plaid suit and the o...</td>\n",
              "      <td>The clowns are in the dressing room.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>A man is playing music with a trumpet.</td>\n",
              "      <td>A man playing music with a guitar.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>A man with a hard hat carries a tree branch.</td>\n",
              "      <td>The man with the hard hat had cut down a tree.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>entailment</td>\n",
              "      <td>An old bearded man holding a fruit.</td>\n",
              "      <td>An elderly bearded man holding a piece of frui...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>A man in a blue coat looks at his feet in a ba...</td>\n",
              "      <td>A man is looking up at the ceiling in a grocer...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99882</th>\n",
              "      <td>entailment</td>\n",
              "      <td>A tribesman makes his way up a tree with his f...</td>\n",
              "      <td>A man is outside climbing a tree.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99883</th>\n",
              "      <td>neutral</td>\n",
              "      <td>A male in a black and white bathing suit, look...</td>\n",
              "      <td>A black male jumping into a backyard pool.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99884</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>The woman sits on the steps outside.</td>\n",
              "      <td>The woman walks along a dirt road.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99885</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>Two people wearing blue clothing are making ha...</td>\n",
              "      <td>A man is sitting with his hands in his pockets.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99886</th>\n",
              "      <td>neutral</td>\n",
              "      <td>People in a marketplace.</td>\n",
              "      <td>The market has just opened for the day, and wi...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99887 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          similarity  ... label\n",
              "0      contradiction  ...     0\n",
              "1      contradiction  ...     0\n",
              "2            neutral  ...     2\n",
              "3         entailment  ...     1\n",
              "4      contradiction  ...     0\n",
              "...              ...  ...   ...\n",
              "99882     entailment  ...     1\n",
              "99883        neutral  ...     2\n",
              "99884  contradiction  ...     0\n",
              "99885  contradiction  ...     0\n",
              "99886        neutral  ...     2\n",
              "\n",
              "[99887 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAQkgH-ZXY2G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465,
          "referenced_widgets": [
            "2afb482534e54d0a9611a775af702fd5",
            "93264af83e8c4dce9ba85765d467a3e8",
            "36300cfec54c44d3b06cda8e10449be0",
            "8a421fd11c834b358aa23e6ed4c2ee31",
            "8545870f3596482394b7751b8fe94970",
            "fc55a32d3a104f2196f1e63ab8f59bc9",
            "f729523d91a242628fbbc83d329c92f4",
            "2e87713dd9f94b77a94f388e72748ed9",
            "90701485ff3549f2a9b973ee19af549b",
            "841a7438f9a64f86bfd162998270066f",
            "38a578b128d049709cc346dc4f72e6a2"
          ]
        },
        "outputId": "1b0ac03f-dbc5-4d7b-de46-80da5ab85fee"
      },
      "source": [
        "mod = SentenceTransformer('msmarco-distilbert-base-dot-prod-v3')\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2afb482534e54d0a9611a775af702fd5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1c4f61aa8484d18a3225ab9b9b4419d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.35k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f3d6a78c1594f48a0dc50ade9cd9ca8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/554 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db2bd9b2381d4dba8e69b90daa82163d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "345c4cb45c9c4fee9304c9a733d74c5e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/341 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3960c5a0862d45d399a0625f3b4745ab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/265M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9a72f5b842d4598afeff87f64ef9e53",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c25d898712a84b7b9980f8286d407cdf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3b75e56951a408991bb3302455ea1c2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd1f9091a14d40a8a17fa971a1c06224",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/376 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f116f4edfa9a400ea67ca037ca34cf63",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dcd793756ae546b5a9342db5102c15d6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac32197c627b4e069b67fc89d379c2a6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/115 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47676c50271249228343b07d056e2a0c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DkVlGgIP4V6"
      },
      "source": [
        "\n",
        "encoded_data = mod.encode(corpus)\n",
        "encoded_data = np.asarray(encoded_data.astype('float32'))\n",
        "index = faiss.IndexIDMap(faiss.IndexFlatIP(768))\n",
        "index.add_with_ids(encoded_data, np.array(range(0, len(corpus))))\n",
        "faiss.write_index(index, 'corpus.index')"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nutLwhL0RXcx"
      },
      "source": [
        "def fetch_movie_info(dataframe_idx):\n",
        "    info = train_df.iloc[dataframe_idx]\n",
        "    meta_dict = dict()\n",
        "    meta_dict['sentence2'] = info['sentence2'][:500]\n",
        "    meta_dict['sentence1'] = info['sentence1'][:500]\n",
        "    return meta_dict\n",
        "    \n",
        "def search(query, top_k, index, model):\n",
        "    t=time.time()\n",
        "    query_vector = model.encode([query])\n",
        "    top_k = index.search(query_vector, top_k)\n",
        "    print('>>>> Results in Total Time: {}'.format(time.time()-t))\n",
        "    top_k_ids = top_k[1].tolist()[0]\n",
        "    top_k_ids = list(np.unique(top_k_ids))\n",
        "    results =  [fetch_movie_info(idx) for idx in top_k_ids]\n",
        "    rdf=pd.DataFrame.from_dict(results)\n",
        "    return rdf"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "CzygcRVlSMTg",
        "outputId": "6245554b-5f0b-45d7-c3dc-a0b18df007ff"
      },
      "source": [
        "\n",
        "query=\"Artificial Intelligence based action\"\n",
        "results=search(query, top_k=5, index=index, model=mod)\n",
        "results"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>> Results in Total Time: 0.029361724853515625\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A man is using a parachute on vacation.</td>\n",
              "      <td>A man using a parachute controlled device goin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Two young girls listening to alien speeches.</td>\n",
              "      <td>Two young girls lay, face down, on grass and f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A man wearing a martial arts uniform and karat...</td>\n",
              "      <td>A man wearing a martial arts uniform is jumpin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The young man is driving a tractor.</td>\n",
              "      <td>a young man playing a motorcycle video game.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>One team practicing rugby.</td>\n",
              "      <td>Players from two teams tangle together in purs...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentence2                                          sentence1\n",
              "0            A man is using a parachute on vacation.  A man using a parachute controlled device goin...\n",
              "1       Two young girls listening to alien speeches.  Two young girls lay, face down, on grass and f...\n",
              "2  A man wearing a martial arts uniform and karat...  A man wearing a martial arts uniform is jumpin...\n",
              "3                The young man is driving a tractor.       a young man playing a motorcycle video game.\n",
              "4                         One team practicing rugby.  Players from two teams tangle together in purs..."
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}